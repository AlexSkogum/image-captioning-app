{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6ed0c36",
   "metadata": {},
   "source": [
    "## Step 1: Verify GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a599d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Device:\", torch.cuda.get_device_name(0))\n",
    "    print(\"GPU Memory:\", torch.cuda.get_device_properties(0).total_memory / 1e9, \"GB\")\n",
    "else:\n",
    "    print(\" No GPU detected!\")\n",
    "    print(\"Go to Runtime → Change runtime type → GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d1ed7",
   "metadata": {},
   "source": [
    "## Step 2: Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f1d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/AlexSkogum/image-captioning-app.git\n",
    "%cd image-captioning-app\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision fastapi gradio pillow pandas numpy requests nltk pyyaml\n",
    "print(\"Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4f0ff9",
   "metadata": {},
   "source": [
    "## Step 3: Configure Kaggle API and Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf94e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "\n",
    "# Option A: Upload kaggle.json from your computer\n",
    "# from google.colab import files\n",
    "# files.upload()  # Select kaggle.json\n",
    "# !mv kaggle.json /root/.kaggle/\n",
    "# !chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "# Option B: Create kaggle.json with your credentials\n",
    "# Replace the values below with your Kaggle credentials\n",
    "kaggle_config = {\n",
    "    \"username\": \"YOUR_KAGGLE_USERNAME\",\n",
    "    \"key\": \"YOUR_KAGGLE_API_KEY\"\n",
    "}\n",
    "\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
    "    json.dump(kaggle_config, f)\n",
    "\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "print(\"Kaggle configured (replace credentials above with your actual keys)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d323c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract Flickr8k dataset\n",
    "!mkdir -p data\n",
    "!kaggle datasets download -d shadabhussain/flickr8k -p data/ --unzip\n",
    "print( Flickr8k dataset downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478d0735",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Dataset and Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e42702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset (creates captions.csv)\n",
    "!python scripts/prepare_flickr8k.py\n",
    "print(\"Dataset prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d627bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary from captions\n",
    "!python scripts/build_vocab.py\n",
    "print(\"Vocabulary built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d819be30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset preparation\n",
    "import pandas as pd\n",
    "\n",
    "if os.path.exists('data/captions.csv'):\n",
    "    df = pd.read_csv('data/captions.csv')\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(\"\\nFirst 3 rows:\")\n",
    "    print(df.head(3))\n",
    "else:\n",
    "    print(\"  captions.csv not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e721fb",
   "metadata": {},
   "source": [
    "## Step 5: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c65dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on GPU\n",
    "!python -m src.train --config configs/config.yaml\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92160be0",
   "metadata": {},
   "source": [
    "## Step 6: Download the Trained Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bac3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "checkpoint_path = 'checkpoints/best.pth'\n",
    "if os.path.exists(checkpoint_path):\n",
    "    files.download(checkpoint_path)\n",
    "    print(f\" Downloaded {checkpoint_path}\")\n",
    "else:\n",
    "    print(f\" Checkpoint not found at {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7d314e",
   "metadata": {},
   "source": [
    "## Next Steps: Use the Trained Model Locally\n",
    "\n",
    "1. **Download** the checkpoint file (`best.pth`) from above\n",
    "2. **Place it** in your local `checkpoints/` folder\n",
    "3. **Restart** your local API and Gradio UI:\n",
    "\n",
    "```bash\n",
    "# Terminal 1: Start API\n",
    "python -m uvicorn src.api.main:app --reload --port 8000\n",
    "\n",
    "# Terminal 2: Start Gradio UI\n",
    "python web/gradio_app.py\n",
    "```\n",
    "\n",
    "Then open: **http://localhost:7860**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
