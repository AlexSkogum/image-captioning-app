{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6ed0c36",
   "metadata": {},
   "source": [
    "## Step 1: Verify GPU Availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d9b17a",
   "metadata": {},
   "source": [
    "## 1. Verify GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ced670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"GPU Status\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(\"✅ GPU is ready!\")\n",
    "else:\n",
    "    print(\"\\n⚠️  WARNING: No GPU detected!\")\n",
    "    print(\"Please go to: Runtime → Change runtime type → Select GPU\")\n",
    "    print(\"Then restart this notebook.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4df1c5",
   "metadata": {},
   "source": [
    "## 2. Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1a1b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Cloning Repository\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if not os.path.exists('/content/image-captioning-app'):\n",
    "    !git clone https://github.com/AlexSkogum/image-captioning-app.git /content/image-captioning-app\n",
    "    print(\"✅ Repository cloned\")\n",
    "else:\n",
    "    print(\"✅ Repository already exists\")\n",
    "\n",
    "os.chdir('/content/image-captioning-app')\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77874d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Installing Dependencies\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q fastapi uvicorn gradio pillow pandas numpy requests nltk pyyaml kaggle\n",
    "\n",
    "print(\"✅ All dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9742aa76",
   "metadata": {},
   "source": [
    "## 3. Setup Kaggle Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Kaggle Credentials Setup\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from google.colab import files\n",
    "import json\n",
    "\n",
    "kaggle_dir = os.path.expanduser('~/.kaggle')\n",
    "os.makedirs(kaggle_dir, exist_ok=True)\n",
    "\n",
    "print(\"\\nChoose one option:\")\n",
    "print(\"[A] Upload kaggle.json from your computer\")\n",
    "print(\"[B] Enter credentials manually\")\n",
    "\n",
    "# Option A: Upload file (uncomment to use)\n",
    "# print(\"\\nUploading kaggle.json...\")\n",
    "# uploaded = files.upload()\n",
    "# for filename in uploaded.keys():\n",
    "#     if filename == 'kaggle.json':\n",
    "#         !mv {filename} {kaggle_dir}/\n",
    "#         !chmod 600 {kaggle_dir}/kaggle.json\n",
    "#         print(\"✅ kaggle.json uploaded and configured\")\n",
    "\n",
    "# Option B: Manual entry (replace with your credentials)\n",
    "kaggle_config = {\n",
    "    \"username\": \"YOUR_KAGGLE_USERNAME\",\n",
    "    \"key\": \"YOUR_KAGGLE_API_KEY\"\n",
    "}\n",
    "\n",
    "config_path = os.path.join(kaggle_dir, 'kaggle.json')\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(kaggle_config, f)\n",
    "\n",
    "!chmod 600 {config_path}\n",
    "print(f\"\\n⚠️  IMPORTANT: Replace YOUR_KAGGLE_USERNAME and YOUR_KAGGLE_API_KEY above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e1735",
   "metadata": {},
   "source": [
    "## 4. Download Flickr8k Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88513547",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Downloading Flickr8k Dataset\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nThis may take 5-10 minutes...\\n\")\n",
    "\n",
    "!mkdir -p data\n",
    "!kaggle datasets download -d shadabhussain/flickr8k -p data/ --unzip\n",
    "\n",
    "if os.path.exists('data/Images') and len(os.listdir('data/Images')) > 0:\n",
    "    print(f\"\\n✅ Dataset downloaded successfully\")\n",
    "    print(f\"Total images: {len(os.listdir('data/Images'))}\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Download may have failed. Check Kaggle credentials above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034886cb",
   "metadata": {},
   "source": [
    "## 5. Prepare Dataset and Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f76efcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Preparing Dataset\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "!python scripts/prepare_flickr8k.py\n",
    "\n",
    "import pandas as pd\n",
    "if os.path.exists('data/captions.csv'):\n",
    "    df = pd.read_csv('data/captions.csv')\n",
    "    print(f\"\\n✅ Dataset prepared successfully\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"\\nFirst 3 samples:\")\n",
    "    print(df.head(3).to_string())\n",
    "else:\n",
    "    print(\"⚠️  captions.csv not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cbe374",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Building Vocabulary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "!python scripts/build_vocab.py\n",
    "\n",
    "import pickle\n",
    "if os.path.exists('data/vocab.pkl'):\n",
    "    with open('data/vocab.pkl', 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    print(f\"\\n✅ Vocabulary built successfully\")\n",
    "    print(f\"Vocabulary size: {len(vocab)}\")\n",
    "else:\n",
    "    print(\"⚠️  vocab.pkl not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d700759",
   "metadata": {},
   "source": [
    "## 6. Train the Model\n",
    "\n",
    "This will train the model on GPU. Estimated time: 10-30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e9bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Training Model on GPU\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nGPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "print(\"\\nTraining will start below...\\n\")\n",
    "\n",
    "!python -m src.train --config configs/config.yaml\n",
    "\n",
    "if os.path.exists('checkpoints/best.pth'):\n",
    "    checkpoint_size = os.path.getsize('checkpoints/best.pth') / 1e6\n",
    "    print(f\"\\n✅ Training complete!\")\n",
    "    print(f\"Checkpoint saved: checkpoints/best.pth ({checkpoint_size:.2f} MB)\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Checkpoint not found. Check training output above for errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65291a0a",
   "metadata": {},
   "source": [
    "## 7. Download the Trained Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a482f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Downloading Checkpoint\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "checkpoint_path = 'checkpoints/best.pth'\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"\\nDownloading {checkpoint_path}...\")\n",
    "    print(\"\\n⏳ The file will appear in your Downloads folder.\\n\")\n",
    "    files.download(checkpoint_path)\n",
    "    print(f\"\\n✅ Download started!\")\n",
    "else:\n",
    "    print(f\"⚠️  Checkpoint not found at {checkpoint_path}\")\n",
    "    print(\"Make sure training completed successfully above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b25466",
   "metadata": {},
   "source": [
    "## 8. Next Steps: Use the Model Locally\n",
    "\n",
    "### Step 1: Download Checkpoint\n",
    "The trained checkpoint should be downloading now.\n",
    "\n",
    "### Step 2: Place in Local Repository\n",
    "```bash\n",
    "# Put best.pth in your local repo:\n",
    "# <your-repo>/checkpoints/best.pth\n",
    "```\n",
    "\n",
    "### Step 3: Run API and Gradio UI Locally\n",
    "```bash\n",
    "# Terminal 1: Start API\n",
    "python -m uvicorn src.api.main:app --reload --port 8000\n",
    "\n",
    "# Terminal 2: Start Gradio UI\n",
    "python web/gradio_app.py\n",
    "```\n",
    "\n",
    "### Step 4: Open in Browser\n",
    "**http://localhost:7860**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65c33f",
   "metadata": {},
   "source": [
    "## 1. Verify GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88639757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"GPU Status\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(\"GPU is ready!\")\n",
    "else:\n",
    "    print(\"\\nWARNING: No GPU detected!\")\n",
    "    print(\"Please go to: Runtime → Change runtime type → Select GPU\")\n",
    "    print(\"Then restart this notebook.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3479b3",
   "metadata": {},
   "source": [
    "## 2. Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d23dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Cloning Repository\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Clone if not already cloned\n",
    "if not os.path.exists('/content/image-captioning-app'):\n",
    "    !git clone https://github.com/AlexSkogum/image-captioning-app.git /content/image-captioning-app\n",
    "    print(\"Repository cloned\")\n",
    "else:\n",
    "    print(\"Repository already exists\")\n",
    "\n",
    "os.chdir('/content/image-captioning-app')\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb1cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Installing Dependencies\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q fastapi uvicorn gradio pillow pandas numpy requests nltk pyyaml kaggle\n",
    "\n",
    "print(\"All dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d74a7",
   "metadata": {},
   "source": [
    "## 3. Setup Kaggle Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca11a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Kaggle Credentials Setup\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from google.colab import files\n",
    "import json\n",
    "\n",
    "# Create .kaggle directory\n",
    "kaggle_dir = os.path.expanduser('~/.kaggle')\n",
    "os.makedirs(kaggle_dir, exist_ok=True)\n",
    "\n",
    "print(\"\\nChoose one option:\")\n",
    "print(\"[A] Upload kaggle.json from your computer\")\n",
    "print(\"[B] Enter credentials manually\")\n",
    "print(\"\\nTo use Option A: Uncomment the code below and run\")\n",
    "print(\"To use Option B: Replace YOUR_USERNAME and YOUR_KEY below\")\n",
    "\n",
    "# Option A: Upload file (uncomment to use)\n",
    "# print(\"\\nUploading kaggle.json...\")\n",
    "# uploaded = files.upload()\n",
    "# for filename in uploaded.keys():\n",
    "#     if filename == 'kaggle.json':\n",
    "#         !mv {filename} {kaggle_dir}/\n",
    "#         !chmod 600 {kaggle_dir}/kaggle.json\n",
    "#         print(\"kaggle.json uploaded and configured\")\n",
    "\n",
    "# Option B: Manual entry (uncomment and fill in your credentials)\n",
    "kaggle_config = {\n",
    "    \"username\": \"YOUR_KAGGLE_USERNAME\",\n",
    "    \"key\": \"YOUR_KAGGLE_API_KEY\"\n",
    "}\n",
    "\n",
    "config_path = os.path.join(kaggle_dir, 'kaggle.json')\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(kaggle_config, f)\n",
    "\n",
    "!chmod 600 {config_path}\n",
    "print(f\"\\nIMPORTANT: Replace credentials in the cell above!\")\n",
    "print(f\"Location: ~/.kaggle/kaggle.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193cb0bd",
   "metadata": {},
   "source": [
    "## 4. Download Flickr8k Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3df5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Downloading Flickr8k Dataset\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nThis may take 5-10 minutes...\\n\")\n",
    "\n",
    "!mkdir -p data\n",
    "!kaggle datasets download -d shadabhussain/flickr8k -p data/ --unzip 2>&1 | grep -E '(Downloading|100%|Unzipping)' || true\n",
    "\n",
    "# Check if download was successful\n",
    "if os.path.exists('data/Images') and len(os.listdir('data/Images')) > 0:\n",
    "    print(f\"Dataset downloaded successfully\")\n",
    "    print(f\"Total images: {len(os.listdir('data/Images'))}\")\n",
    "else:\n",
    "    print(\"Download may have failed. Check Kaggle credentials above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55102c6",
   "metadata": {},
   "source": [
    "## 5. Prepare Dataset and Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b01be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Preparing Dataset\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Run dataset preparation script\n",
    "!python scripts/prepare_flickr8k.py\n",
    "\n",
    "# Verify captions.csv was created\n",
    "import pandas as pd\n",
    "if os.path.exists('data/captions.csv'):\n",
    "    df = pd.read_csv('data/captions.csv')\n",
    "    print(f\"\\nDataset prepared successfully\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"\\nFirst 3 samples:\")\n",
    "    print(df.head(3).to_string())\n",
    "else:\n",
    "    print(\"captions.csv not found. Check prepare_flickr8k.py script.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a39925",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Building Vocabulary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "!python scripts/build_vocab.py\n",
    "\n",
    "# Check vocab file\n",
    "import pickle\n",
    "if os.path.exists('data/vocab.pkl'):\n",
    "    with open('data/vocab.pkl', 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    print(f\"\\n✅ Vocabulary built successfully\")\n",
    "    print(f\"Vocabulary size: {len(vocab)}\")\n",
    "else:\n",
    "    print(\"vocab.pkl not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e12e0",
   "metadata": {},
   "source": [
    "## 6. Train the Model\n",
    "\n",
    "This will train the model on GPU. Estimated time: 10-30 minutes depending on epochs and batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70828489",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Training Model on GPU\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nGPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "print(\"\\nTraining will start below...\\n\")\n",
    "\n",
    "# Run training\n",
    "!python -m src.train --config configs/config.yaml 2>&1\n",
    "\n",
    "# Verify checkpoint was saved\n",
    "if os.path.exists('checkpoints/best.pth'):\n",
    "    checkpoint_size = os.path.getsize('checkpoints/best.pth') / 1e6\n",
    "    print(f\"\\nTraining complete!\")\n",
    "    print(f\"Checkpoint saved: checkpoints/best.pth ({checkpoint_size:.2f} MB)\")\n",
    "else:\n",
    "    print(\"\\nCheckpoint not found. Check training output above for errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1f2f55",
   "metadata": {},
   "source": [
    "## 7. Download the Trained Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0727c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Downloading Checkpoint\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "checkpoint_path = 'checkpoints/best.pth'\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"\\nDownloading {checkpoint_path}...\")\n",
    "    print(\"\\n⏳ The file will appear in your Downloads folder in a few seconds.\\n\")\n",
    "    files.download(checkpoint_path)\n",
    "    print(f\"\\nDownload started!\")\n",
    "else:\n",
    "    print(f\"Checkpoint not found at {checkpoint_path}\")\n",
    "    print(\"\\nMake sure training completed successfully above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff33b126",
   "metadata": {},
   "source": [
    "## 8. Next Steps: Use the Model Locally\n",
    "\n",
    "### Step 1: Download Checkpoint\n",
    "The trained checkpoint should be downloading to your computer right now.\n",
    "\n",
    "### Step 2: Place in Local Repository\n",
    "```bash\n",
    "# After downloading, place best.pth in your local repo:\n",
    "# <your-repo>/checkpoints/best.pth\n",
    "```\n",
    "\n",
    "### Step 3: Run API and Gradio UI Locally\n",
    "```bash\n",
    "# Terminal 1: Start API\n",
    "python -m uvicorn src.api.main:app --reload --port 8000\n",
    "\n",
    "# Terminal 2: Start Gradio UI\n",
    "python web/gradio_app.py\n",
    "```\n",
    "\n",
    "### Step 4: Open in Browser\n",
    "**http://localhost:7860**\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    ",\n",
    ",\n",
    "3\n",
    ","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a599d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: False\n",
      " No GPU detected!\n",
      "Go to Runtime → Change runtime type → GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"GPU Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Device:\", torch.cuda.get_device_name(0))\n",
    "    print(\"GPU Memory:\", torch.cuda.get_device_properties(0).total_memory / 1e9, \"GB\")\n",
    "else:\n",
    "    print(\" No GPU detected!\")\n",
    "    print(\"Go to Runtime → Change runtime type → GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d1ed7",
   "metadata": {},
   "source": [
    "## Step 2: Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46f1d6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexa\\image_captioning_app\\image-captioning-app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'image-captioning-app' already exists and is not an empty directory.\n",
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/AlexSkogum/image-captioning-app.git\n",
    "%cd image-captioning-app\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4608b327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies installed\n"
     ]
    }
   ],
   "source": [
    "!pip install -q torch torchvision fastapi gradio pillow pandas numpy requests nltk pyyaml\n",
    "print(\"Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4f0ff9",
   "metadata": {},
   "source": [
    "## Step 3: Configure Kaggle API and Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf94e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle configured (replace credentials above with your actual keys)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'chmod' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "\n",
    "# Option A: Upload kaggle.json from your computer\n",
    "# from google.colab import files\n",
    "# files.upload()  # Select kaggle.json\n",
    "# !mv kaggle.json /root/.kaggle/\n",
    "# !chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "# Option B: Create kaggle.json with your credentials\n",
    "# Replace the values below with your Kaggle credentials\n",
    "kaggle_config = {\n",
    "    \"username\": \"YOUR_KAGGLE_USERNAME\",\n",
    "    \"key\": \"YOUR_KAGGLE_API_KEY\"\n",
    "}\n",
    "\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
    "    json.dump(kaggle_config, f)\n",
    "\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "print(\"Kaggle configured (replace credentials above with your actual keys)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d323c5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Flickr8k dataset downloaded\n",
      "Flickr8k dataset downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/2.13G [00:00<?, ?B/s]\n",
      "  1%|          | 12.0M/2.13G [00:00<00:19, 114MB/s]\n",
      "  1%|          | 24.0M/2.13G [00:00<00:18, 119MB/s]\n",
      "  2%|▏         | 36.0M/2.13G [00:00<00:19, 116MB/s]\n",
      "  2%|▏         | 48.0M/2.13G [00:00<00:19, 116MB/s]\n",
      "  3%|▎         | 60.0M/2.13G [00:00<00:18, 119MB/s]\n",
      "  3%|▎         | 72.0M/2.13G [00:00<00:18, 120MB/s]\n",
      "  4%|▍         | 84.0M/2.13G [00:00<00:20, 107MB/s]\n",
      "  4%|▍         | 96.0M/2.13G [00:00<00:19, 110MB/s]\n",
      "  5%|▍         | 107M/2.13G [00:01<00:21, 102MB/s] \n",
      "  5%|▌         | 117M/2.13G [00:01<00:21, 101MB/s]\n",
      "  6%|▌         | 128M/2.13G [00:01<00:22, 97.5MB/s]\n",
      "  6%|▋         | 139M/2.13G [00:01<00:21, 101MB/s] \n",
      "  7%|▋         | 152M/2.13G [00:01<00:19, 110MB/s]\n",
      "  8%|▊         | 164M/2.13G [00:01<00:19, 111MB/s]\n",
      "  8%|▊         | 175M/2.13G [00:01<00:20, 104MB/s]\n",
      "  9%|▊         | 188M/2.13G [00:01<00:20, 99.6MB/s]\n",
      "  9%|▉         | 201M/2.13G [00:01<00:19, 108MB/s] \n",
      " 10%|▉         | 212M/2.13G [00:02<00:26, 78.6MB/s]\n",
      " 10%|█         | 225M/2.13G [00:02<00:22, 89.5MB/s]\n",
      " 11%|█         | 235M/2.13G [00:02<00:48, 42.1MB/s]\n",
      " 11%|█▏        | 249M/2.13G [00:03<00:36, 55.6MB/s]\n",
      " 12%|█▏        | 259M/2.13G [00:03<00:31, 63.2MB/s]\n",
      " 12%|█▏        | 269M/2.13G [00:03<00:29, 68.7MB/s]\n",
      " 13%|█▎        | 279M/2.13G [00:03<00:30, 65.5MB/s]\n",
      " 13%|█▎        | 291M/2.13G [00:03<00:26, 75.8MB/s]\n",
      " 14%|█▍        | 301M/2.13G [00:03<00:25, 78.8MB/s]\n",
      " 14%|█▍        | 313M/2.13G [00:03<00:22, 88.0MB/s]\n",
      " 15%|█▌        | 328M/2.13G [00:03<00:18, 103MB/s] \n",
      " 16%|█▌        | 341M/2.13G [00:03<00:17, 111MB/s]\n",
      " 16%|█▋        | 359M/2.13G [00:04<00:14, 131MB/s]\n",
      " 17%|█▋        | 373M/2.13G [00:04<00:16, 114MB/s]\n",
      " 18%|█▊        | 385M/2.13G [00:04<00:16, 116MB/s]\n",
      " 18%|█▊        | 397M/2.13G [00:04<00:17, 105MB/s]\n",
      " 19%|█▉        | 409M/2.13G [00:04<00:16, 110MB/s]\n",
      " 19%|█▉        | 421M/2.13G [00:04<00:16, 113MB/s]\n",
      " 20%|█▉        | 434M/2.13G [00:04<00:16, 112MB/s]\n",
      " 21%|██        | 447M/2.13G [00:04<00:17, 102MB/s]\n",
      " 21%|██        | 463M/2.13G [00:05<00:15, 116MB/s]\n",
      " 22%|██▏       | 475M/2.13G [00:05<00:15, 115MB/s]\n",
      " 22%|██▏       | 487M/2.13G [00:05<00:16, 111MB/s]\n",
      " 23%|██▎       | 498M/2.13G [00:05<00:16, 106MB/s]\n",
      " 23%|██▎       | 509M/2.13G [00:05<00:17, 102MB/s]\n",
      " 24%|██▍       | 529M/2.13G [00:05<00:13, 125MB/s]\n",
      " 25%|██▍       | 544M/2.13G [00:05<00:12, 133MB/s]\n",
      " 26%|██▌       | 562M/2.13G [00:05<00:11, 145MB/s]\n",
      " 26%|██▋       | 577M/2.13G [00:06<00:12, 139MB/s]\n",
      " 27%|██▋       | 591M/2.13G [00:06<00:12, 136MB/s]\n",
      " 28%|██▊       | 610M/2.13G [00:06<00:10, 152MB/s]\n",
      " 29%|██▊       | 625M/2.13G [00:06<00:11, 139MB/s]\n",
      " 29%|██▉       | 639M/2.13G [00:06<00:11, 138MB/s]\n",
      " 30%|██▉       | 653M/2.13G [00:06<00:11, 135MB/s]\n",
      " 31%|███       | 666M/2.13G [00:06<00:12, 126MB/s]\n",
      " 31%|███▏      | 683M/2.13G [00:06<00:11, 139MB/s]\n",
      " 32%|███▏      | 697M/2.13G [00:06<00:11, 138MB/s]\n",
      " 33%|███▎      | 711M/2.13G [00:07<00:11, 137MB/s]\n",
      " 33%|███▎      | 725M/2.13G [00:07<00:11, 130MB/s]\n",
      " 34%|███▍      | 738M/2.13G [00:07<00:22, 67.2MB/s]\n",
      " 35%|███▍      | 754M/2.13G [00:07<00:18, 82.9MB/s]\n",
      " 35%|███▌      | 766M/2.13G [00:08<00:30, 49.4MB/s]\n",
      " 36%|███▌      | 782M/2.13G [00:08<00:22, 64.4MB/s]\n",
      " 37%|███▋      | 796M/2.13G [00:08<00:19, 76.3MB/s]\n",
      " 37%|███▋      | 808M/2.13G [00:08<00:17, 81.5MB/s]\n",
      " 38%|███▊      | 820M/2.13G [00:09<00:24, 58.0MB/s]\n",
      " 38%|███▊      | 834M/2.13G [00:09<00:19, 71.3MB/s]\n",
      " 39%|███▉      | 850M/2.13G [00:09<00:16, 85.1MB/s]\n",
      " 40%|███▉      | 862M/2.13G [00:09<00:14, 92.6MB/s]\n",
      " 40%|████      | 877M/2.13G [00:09<00:13, 104MB/s] \n",
      " 41%|████      | 889M/2.13G [00:09<00:13, 101MB/s]\n",
      " 42%|████▏     | 906M/2.13G [00:09<00:11, 119MB/s]\n",
      " 42%|████▏     | 919M/2.13G [00:09<00:10, 123MB/s]\n",
      " 43%|████▎     | 932M/2.13G [00:09<00:10, 122MB/s]\n",
      " 43%|████▎     | 945M/2.13G [00:10<00:10, 118MB/s]\n",
      " 44%|████▍     | 957M/2.13G [00:10<00:11, 111MB/s]\n",
      " 45%|████▍     | 978M/2.13G [00:10<00:09, 138MB/s]\n",
      " 46%|████▌     | 992M/2.13G [00:10<00:08, 140MB/s]\n",
      " 46%|████▌     | 0.98G/2.13G [00:10<00:09, 136MB/s]\n",
      " 47%|████▋     | 1.00G/2.13G [00:10<00:09, 130MB/s]\n",
      " 47%|████▋     | 1.01G/2.13G [00:10<00:10, 116MB/s]\n",
      " 48%|████▊     | 1.02G/2.13G [00:10<00:10, 114MB/s]\n",
      " 49%|████▊     | 1.03G/2.13G [00:11<00:10, 111MB/s]\n",
      " 49%|████▉     | 1.05G/2.13G [00:11<00:10, 113MB/s]\n",
      " 50%|████▉     | 1.06G/2.13G [00:11<00:10, 105MB/s]\n",
      " 50%|█████     | 1.07G/2.13G [00:11<00:09, 114MB/s]\n",
      " 51%|█████     | 1.09G/2.13G [00:11<00:19, 56.7MB/s]\n",
      " 52%|█████▏    | 1.10G/2.13G [00:12<00:15, 70.2MB/s]\n",
      " 52%|█████▏    | 1.11G/2.13G [00:12<00:12, 85.2MB/s]\n",
      " 53%|█████▎    | 1.13G/2.13G [00:12<00:11, 93.1MB/s]\n",
      " 53%|█████▎    | 1.14G/2.13G [00:12<00:10, 99.9MB/s]\n",
      " 54%|█████▍    | 1.15G/2.13G [00:12<00:09, 108MB/s] \n",
      " 55%|█████▍    | 1.16G/2.13G [00:12<00:10, 104MB/s]\n",
      " 55%|█████▌    | 1.18G/2.13G [00:12<00:09, 109MB/s]\n",
      " 56%|█████▌    | 1.19G/2.13G [00:12<00:08, 121MB/s]\n",
      " 57%|█████▋    | 1.21G/2.13G [00:12<00:07, 124MB/s]\n",
      " 58%|█████▊    | 1.22G/2.13G [00:13<00:07, 129MB/s]\n",
      " 58%|█████▊    | 1.24G/2.13G [00:13<00:07, 131MB/s]\n",
      " 59%|█████▊    | 1.25G/2.13G [00:13<00:07, 125MB/s]\n",
      " 59%|█████▉    | 1.26G/2.13G [00:13<00:10, 88.7MB/s]\n",
      " 60%|█████▉    | 1.27G/2.13G [00:13<00:16, 55.6MB/s]\n",
      " 61%|██████    | 1.29G/2.13G [00:14<00:12, 72.2MB/s]\n",
      " 61%|██████    | 1.30G/2.13G [00:14<00:11, 76.1MB/s]\n",
      " 62%|██████▏   | 1.31G/2.13G [00:14<00:09, 93.7MB/s]\n",
      " 62%|██████▏   | 1.33G/2.13G [00:14<00:08, 97.4MB/s]\n",
      " 63%|██████▎   | 1.34G/2.13G [00:14<00:15, 53.9MB/s]\n",
      " 64%|██████▎   | 1.35G/2.13G [00:14<00:12, 68.9MB/s]\n",
      " 64%|██████▍   | 1.37G/2.13G [00:15<00:10, 80.4MB/s]\n",
      " 65%|██████▍   | 1.38G/2.13G [00:15<00:08, 90.9MB/s]\n",
      " 65%|██████▌   | 1.39G/2.13G [00:15<00:08, 97.2MB/s]\n",
      " 66%|██████▌   | 1.40G/2.13G [00:15<00:07, 99.2MB/s]\n",
      " 66%|██████▋   | 1.41G/2.13G [00:15<00:07, 103MB/s] \n",
      " 67%|██████▋   | 1.42G/2.13G [00:15<00:07, 105MB/s]\n",
      " 68%|██████▊   | 1.44G/2.13G [00:15<00:06, 111MB/s]\n",
      " 68%|██████▊   | 1.45G/2.13G [00:15<00:06, 115MB/s]\n",
      " 69%|██████▉   | 1.46G/2.13G [00:16<00:06, 113MB/s]\n",
      " 69%|██████▉   | 1.48G/2.13G [00:16<00:06, 114MB/s]\n",
      " 70%|██████▉   | 1.49G/2.13G [00:16<00:05, 116MB/s]\n",
      " 70%|███████   | 1.50G/2.13G [00:16<00:05, 119MB/s]\n",
      " 71%|███████   | 1.51G/2.13G [00:16<00:06, 109MB/s]\n",
      " 72%|███████▏  | 1.53G/2.13G [00:16<00:05, 127MB/s]\n",
      " 72%|███████▏  | 1.54G/2.13G [00:16<00:04, 128MB/s]\n",
      " 73%|███████▎  | 1.55G/2.13G [00:16<00:04, 125MB/s]\n",
      " 74%|███████▎  | 1.57G/2.13G [00:16<00:04, 123MB/s]\n",
      " 74%|███████▍  | 1.58G/2.13G [00:17<00:05, 112MB/s]\n",
      " 75%|███████▍  | 1.59G/2.13G [00:17<00:05, 111MB/s]\n",
      " 75%|███████▌  | 1.60G/2.13G [00:17<00:05, 107MB/s]\n",
      " 76%|███████▌  | 1.61G/2.13G [00:17<00:07, 73.7MB/s]\n",
      " 76%|███████▌  | 1.62G/2.13G [00:19<00:37, 14.5MB/s]\n",
      " 77%|███████▋  | 1.63G/2.13G [00:19<00:30, 17.4MB/s]\n",
      " 77%|███████▋  | 1.64G/2.13G [00:20<00:21, 24.5MB/s]\n",
      " 78%|███████▊  | 1.65G/2.13G [00:20<00:15, 32.8MB/s]\n",
      " 78%|███████▊  | 1.66G/2.13G [00:20<00:11, 42.2MB/s]\n",
      " 79%|███████▊  | 1.67G/2.13G [00:20<00:10, 48.4MB/s]\n",
      " 79%|███████▉  | 1.69G/2.13G [00:20<00:07, 62.9MB/s]\n",
      " 80%|████████  | 1.70G/2.13G [00:20<00:05, 81.1MB/s]\n",
      " 81%|████████  | 1.71G/2.13G [00:20<00:05, 87.1MB/s]\n",
      " 81%|████████  | 1.73G/2.13G [00:20<00:04, 88.6MB/s]\n",
      " 82%|████████▏ | 1.74G/2.13G [00:21<00:04, 92.1MB/s]\n",
      " 82%|████████▏ | 1.75G/2.13G [00:21<00:03, 106MB/s] \n",
      " 83%|████████▎ | 1.77G/2.13G [00:21<00:03, 105MB/s]\n",
      " 84%|████████▎ | 1.78G/2.13G [00:21<00:03, 107MB/s]\n",
      " 84%|████████▍ | 1.79G/2.13G [00:21<00:03, 114MB/s]\n",
      " 85%|████████▍ | 1.80G/2.13G [00:21<00:05, 66.3MB/s]\n",
      " 86%|████████▌ | 1.82G/2.13G [00:22<00:03, 87.4MB/s]\n",
      " 87%|████████▋ | 1.86G/2.13G [00:22<00:01, 154MB/s] \n",
      " 89%|████████▊ | 1.89G/2.13G [00:22<00:01, 178MB/s]\n",
      " 90%|█████████ | 1.92G/2.13G [00:22<00:01, 206MB/s]\n",
      " 92%|█████████▏| 1.95G/2.13G [00:22<00:00, 245MB/s]\n",
      " 93%|█████████▎| 1.98G/2.13G [00:22<00:00, 258MB/s]\n",
      " 94%|█████████▍| 2.01G/2.13G [00:23<00:00, 137MB/s]\n",
      " 95%|█████████▌| 2.03G/2.13G [00:23<00:01, 101MB/s]\n",
      " 97%|█████████▋| 2.06G/2.13G [00:23<00:00, 134MB/s]\n",
      " 98%|█████████▊| 2.09G/2.13G [00:23<00:00, 151MB/s]\n",
      " 99%|█████████▉| 2.11G/2.13G [00:23<00:00, 174MB/s]\n",
      "100%|██████████| 2.13G/2.13G [00:23<00:00, 96.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/shadabhussain/flickr8k\n",
      "License(s): unknown\n",
      "Downloading flickr8k.zip to data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download and extract Flickr8k dataset\n",
    "!mkdir -p data\n",
    "!kaggle datasets download -d shadabhussain/flickr8k -p data/ --unzip\n",
    "print(\"Flickr8k dataset downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478d0735",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Dataset and Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e42702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset (creates captions.csv)\n",
    "!python scripts/prepare_flickr8k.py\n",
    "print(\"Dataset prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d627bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary from captions\n",
    "!python scripts/build_vocab.py\n",
    "print(\"Vocabulary built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d819be30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset preparation\n",
    "import pandas as pd\n",
    "\n",
    "if os.path.exists('data/captions.csv'):\n",
    "    df = pd.read_csv('data/captions.csv')\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(\"\\nFirst 3 rows:\")\n",
    "    print(df.head(3))\n",
    "else:\n",
    "    print(\"  captions.csv not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e721fb",
   "metadata": {},
   "source": [
    "## Step 5: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d35c65dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\alexa\\image_captioning_app\\image-captioning-app\\src\\train.py\", line 85, in <module>\n",
      "    main()\n",
      "  File \"c:\\Users\\alexa\\image_captioning_app\\image-captioning-app\\src\\train.py\", line 60, in main\n",
      "    vocab = Vocabulary.load('data/vocab.pkl')\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\alexa\\image_captioning_app\\image-captioning-app\\src\\data.py\", line 67, in load\n",
      "    with open(path, 'rb') as f:\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/vocab.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Train the model on GPU\n",
    "!python -m src.train --config configs/config.yaml\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92160be0",
   "metadata": {},
   "source": [
    "## Step 6: Download the Trained Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bac3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "checkpoint_path = 'checkpoints/best.pth'\n",
    "if os.path.exists(checkpoint_path):\n",
    "    files.download(checkpoint_path)\n",
    "    print(f\" Downloaded {checkpoint_path}\")\n",
    "else:\n",
    "    print(f\" Checkpoint not found at {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7d314e",
   "metadata": {},
   "source": [
    "## Next Steps: Use the Trained Model Locally\n",
    "\n",
    "1. **Download** the checkpoint file (`best.pth`) from above\n",
    "2. **Place it** in your local `checkpoints/` folder\n",
    "3. **Restart** your local API and Gradio UI:\n",
    "\n",
    "```bash\n",
    "# Terminal 1: Start API\n",
    "python -m uvicorn src.api.main:app --reload --port 8000\n",
    "\n",
    "# Terminal 2: Start Gradio UI\n",
    "python web/gradio_app.py\n",
    "```\n",
    "\n",
    "Then open: **http://localhost:7860**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
